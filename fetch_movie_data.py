import requests
import json
import os
from typing import Dict, List, Any

class MovieDataFetcher:
  def __init__(self, api_key: str):
      self.api_key = api_key
      self.base_url = "https://api.themoviedb.org/3"
      self.session = requests.Session()
  
  def get_trending_data(self) -> Dict[str, Any]:
      """è·å–çƒ­é—¨è¶‹åŠ¿æ•°æ®"""
      url = f"{self.base_url}/trending/all/day"
      params = {
          'api_key': self.api_key,
          'language': 'zh-CN',
          'append_to_response': 'images'
      }
      
      try:
          response = self.session.get(url, params=params)
          response.raise_for_status()
          return response.json()
      except requests.RequestException as e:
          print(f"è·å–è¶‹åŠ¿æ•°æ®å¤±è´¥: {e}")
          return {}
  
  def get_movie_details(self, movie_id: int) -> Dict[str, Any]:
      """è·å–ç”µå½±è¯¦ç»†ä¿¡æ¯"""
      url = f"{self.base_url}/movie/{movie_id}"
      params = {
          'api_key': self.api_key,
          'append_to_response': 'images,credits,videos'
      }
      
      try:
          response = self.session.get(url, params=params)
          response.raise_for_status()
          return response.json()
      except requests.RequestException as e:
          print(f"è·å–ç”µå½± {movie_id} è¯¦ç»†ä¿¡æ¯å¤±è´¥: {e}")
          return {}
  
  def get_tv_details(self, tv_id: int) -> Dict[str, Any]:
      """è·å–ç”µè§†å‰§è¯¦ç»†ä¿¡æ¯"""
      url = f"{self.base_url}/tv/{tv_id}"
      params = {
          'api_key': self.api_key,
          'append_to_response': 'images,credits,videos'
      }
      
      try:
          response = self.session.get(url, params=params)
          response.raise_for_status()
          return response.json()
      except requests.RequestException as e:
          print(f"è·å–ç”µè§†å‰§ {tv_id} è¯¦ç»†ä¿¡æ¯å¤±è´¥: {e}")
          return {}
  
  def filter_and_sort_images(self, images: List[Dict[str, Any]], image_type: str = "") -> List[Dict[str, Any]]:
      """
      è¿‡æ»¤å’Œæ’åºå›¾ç‰‡
      - åªä¿ç•™ iso_639_1='zh' æˆ– iso_639_1=null çš„å›¾ç‰‡
      - æŒ‰ width å€’åºæ’åº
      - æ¯ä¸ª iso_639_1 ç±»å‹å–å‰2å¼ 
      """
      if not images:
          return []
      
      # è¿‡æ»¤å›¾ç‰‡ï¼šåªä¿ç•™ä¸­æ–‡æˆ–æ— è¯­è¨€æ ‡è¯†çš„å›¾ç‰‡
      filtered_images = []
      for img in images:
          iso_639_1 = img.get('iso_639_1')
          if iso_639_1 == 'zh' or iso_639_1 is None:
              filtered_images.append(img)
      
      if not filtered_images:
          return []
      
      # æŒ‰ iso_639_1 åˆ†ç»„
      zh_images = [img for img in filtered_images if img.get('iso_639_1') == 'zh']
      null_images = [img for img in filtered_images if img.get('iso_639_1') is None]
      
      # æŒ‰ width å€’åºæ’åºå¹¶å–å‰2å¼ 
      def sort_by_width_desc(img_list):
          return sorted(img_list, key=lambda x: x.get('width', 0), reverse=True)[:2]
      
      result_images = []
      
      # å¤„ç†ä¸­æ–‡å›¾ç‰‡
      if zh_images:
          sorted_zh = sort_by_width_desc(zh_images)
          result_images.extend(sorted_zh)
          print(f"  æ‰¾åˆ° {len(zh_images)} å¼ ä¸­æ–‡{image_type}å›¾ç‰‡ï¼Œé€‰æ‹©äº†å‰ {len(sorted_zh)} å¼ ")
      
      # å¤„ç†æ— è¯­è¨€æ ‡è¯†å›¾ç‰‡
      if null_images:
          sorted_null = sort_by_width_desc(null_images)
          result_images.extend(sorted_null)
          print(f"  æ‰¾åˆ° {len(null_images)} å¼ æ— è¯­è¨€{image_type}å›¾ç‰‡ï¼Œé€‰æ‹©äº†å‰ {len(sorted_null)} å¼ ")
      
      return result_images
  
  def merge_item_data(self, basic_item: Dict[str, Any], details: Dict[str, Any]) -> Dict[str, Any]:
      """åˆå¹¶åŸºç¡€æ•°æ®å’Œè¯¦ç»†æ•°æ®"""
      # ä»åŸºç¡€æ•°æ®å¼€å§‹
      merged_item = {
          'id': basic_item.get('id'),
          'media_type': basic_item.get('media_type'),
          'title': basic_item.get('title') or basic_item.get('name'),
          'original_title': basic_item.get('original_title') or basic_item.get('original_name'),
          'overview': basic_item.get('overview'),
          'poster_path': basic_item.get('poster_path'),
          'backdrop_path': basic_item.get('backdrop_path'),
          'vote_average': basic_item.get('vote_average'),
          'vote_count': basic_item.get('vote_count'),
          'popularity': basic_item.get('popularity'),
          'release_date': basic_item.get('release_date') or basic_item.get('first_air_date'),
          'genre_ids': basic_item.get('genre_ids', []),
          'adult': basic_item.get('adult', False),
      }
      
      # æ·»åŠ è¯¦ç»†ä¿¡æ¯å­—æ®µ
      if details:
          # é€šç”¨å­—æ®µ
          merged_item.update({
              'budget': details.get('budget'),  # ç”µå½±é¢„ç®—
              'revenue': details.get('revenue'),  # ç”µå½±æ”¶å…¥
              'runtime': details.get('runtime'),  # ç”µå½±æ—¶é•¿
              'status': details.get('status'),  # çŠ¶æ€
              'tagline': details.get('tagline'),  # æ ‡è¯­
              'homepage': details.get('homepage'),  # å®˜æ–¹ç½‘ç«™
              'imdb_id': details.get('imdb_id'),  # IMDB ID
              'original_language': details.get('original_language'),  # åŸå§‹è¯­è¨€
              'spoken_languages': details.get('spoken_languages', []),  # è¯­è¨€åˆ—è¡¨
              'production_companies': details.get('production_companies', []),  # åˆ¶ä½œå…¬å¸
              'production_countries': details.get('production_countries', []),  # åˆ¶ä½œå›½å®¶
              'genres': details.get('genres', []),  # è¯¦ç»†ç±»å‹ä¿¡æ¯
          })
          
          # ç”µè§†å‰§ç‰¹æœ‰å­—æ®µ
          if basic_item.get('media_type') == 'tv':
              merged_item.update({
                  'first_air_date': details.get('first_air_date'),
                  'last_air_date': details.get('last_air_date'),
                  'number_of_episodes': details.get('number_of_episodes'),
                  'number_of_seasons': details.get('number_of_seasons'),
                  'episode_run_time': details.get('episode_run_time', []),
                  'in_production': details.get('in_production'),
                  'languages': details.get('languages', []),
                  'last_episode_to_air': details.get('last_episode_to_air'),
                  'next_episode_to_air': details.get('next_episode_to_air'),
                  'networks': details.get('networks', []),
                  'origin_country': details.get('origin_country', []),
                  'seasons': details.get('seasons', []),
                  'type': details.get('type'),
              })
          
          # ç”µå½±ç‰¹æœ‰å­—æ®µ
          elif basic_item.get('media_type') == 'movie':
              merged_item.update({
                  'belongs_to_collection': details.get('belongs_to_collection'),
                  'release_date': details.get('release_date'),
              })
          
          # æ¼”èŒå‘˜ä¿¡æ¯
          if 'credits' in details:
              credits = details['credits']
              merged_item.update({
                  'cast': credits.get('cast', [])[:5],  # åªä¿ç•™å‰5ä¸ªæ¼”å‘˜
                  'crew': credits.get('crew', [])[:5],  # åªä¿ç•™å‰5ä¸ªå·¥ä½œäººå‘˜
              })
          
          # è§†é¢‘ä¿¡æ¯
          if 'videos' in details and details['videos'].get('results'):
              merged_item['videos'] = details['videos']['results'][:5]  # åªä¿ç•™å‰5ä¸ªè§†é¢‘
          
          # å›¾ç‰‡ä¿¡æ¯ - ä½¿ç”¨æ–°çš„è¿‡æ»¤å’Œæ’åºé€»è¾‘
          if 'images' in details:
              images = details['images']
              item_title = merged_item.get('title', 'Unknown')
              
              print(f"å¤„ç† {item_title} çš„å›¾ç‰‡:")
              
              # å¤„ç†èƒŒæ™¯å›¾ç‰‡
              if 'backdrops' in images:
                  filtered_backdrops = self.filter_and_sort_images(images['backdrops'], 'èƒŒæ™¯')
                  if filtered_backdrops:
                      merged_item['backdrops'] = filtered_backdrops
              
              # å¤„ç†æµ·æŠ¥å›¾ç‰‡
              if 'posters' in images:
                  filtered_posters = self.filter_and_sort_images(images['posters'], 'æµ·æŠ¥')
                  if filtered_posters:
                      merged_item['posters'] = filtered_posters
              
              # å¤„ç†logoså›¾ç‰‡
              if 'logos' in images:
                  filtered_logos = self.filter_and_sort_images(images['logos'], 'logos')
                  if filtered_logos:
                      merged_item['logos'] = filtered_logos
      
      # ç§»é™¤å€¼ä¸º None çš„å­—æ®µ
      return {k: v for k, v in merged_item.items() if v is not None}
  
  def process_trending_items(self, trending_data: Dict[str, Any]) -> List[Dict[str, Any]]:
      """å¤„ç†è¶‹åŠ¿æ•°æ®ï¼Œè·å–è¯¦ç»†ä¿¡æ¯"""
      if 'results' not in trending_data:
          return []
      
      processed_items = []
      
      for item in trending_data['results']:
          media_type = item.get('media_type')
          item_id = item.get('id')
          
          if not item_id:
              continue
          
          # è·å–è¯¦ç»†ä¿¡æ¯
          if media_type == 'movie':
              details = self.get_movie_details(item_id)
          elif media_type == 'tv':
              details = self.get_tv_details(item_id)
          else:
              continue
          
          # åˆå¹¶åŸºç¡€ä¿¡æ¯å’Œè¯¦ç»†ä¿¡æ¯
          merged_item = self.merge_item_data(item, details)
          
          if merged_item:
              processed_items.append(merged_item)
              print(f"âœ… å·²å¤„ç† {media_type}: {merged_item['title']} (ID: {item_id})")
              print("---")
      
      return processed_items
  
  def generate_homepage_data(self) -> List[Dict[str, Any]]:
      """ç”Ÿæˆä¸»é¡µæ•°æ® - åªè¿”å›itemsæ•°ç»„"""
      print("å¼€å§‹è·å–è¶‹åŠ¿æ•°æ®...")
      trending_data = self.get_trending_data()
      
      if not trending_data:
          print("æœªèƒ½è·å–åˆ°è¶‹åŠ¿æ•°æ®")
          return []
      
      print(f"è·å–åˆ° {len(trending_data.get('results', []))} ä¸ªè¶‹åŠ¿é¡¹ç›®")
      print("=" * 50)
      
      print("å¼€å§‹å¤„ç†è¯¦ç»†ä¿¡æ¯...")
      processed_items = self.process_trending_items(trending_data)
      
      return processed_items
  
  def save_to_file(self, data: List[Dict[str, Any]], filename: str = 'homepage.json'):
      """ä¿å­˜æ•°æ®åˆ°æ–‡ä»¶"""
      try:
          with open(filename, 'w', encoding='utf-8') as f:
              json.dump(data, f, ensure_ascii=False, indent=2)
          print("=" * 50)
          print(f"âœ… æ•°æ®å·²ä¿å­˜åˆ° {filename}")
          print(f"ğŸ“Š å…±ä¿å­˜äº† {len(data)} ä¸ªé¡¹ç›®")
          
          # ç»Ÿè®¡å›¾ç‰‡ä¿¡æ¯
          total_backdrops = sum(len(item.get('backdrops', [])) for item in data)
          total_posters = sum(len(item.get('posters', [])) for item in data)
          print(f"ğŸ–¼ï¸  å…±åŒ…å« {total_backdrops} å¼ èƒŒæ™¯å›¾ç‰‡ï¼Œ{total_posters} å¼ æµ·æŠ¥å›¾ç‰‡")
          
      except Exception as e:
          print(f"âŒ ä¿å­˜æ–‡ä»¶å¤±è´¥: {e}")

def main():
  # ä»ç¯å¢ƒå˜é‡è·å– API å¯†é’¥
  api_key = os.getenv('TMDB_API_KEY', '9f10dfe93f1fd3b793eaa10c732a07e9')
  
  if not api_key:
      print("âŒ é”™è¯¯: æœªæ‰¾åˆ° TMDB API å¯†é’¥")
      return
  
  fetcher = MovieDataFetcher(api_key)
  
  print("ğŸ¬ å¼€å§‹ç”Ÿæˆä¸»é¡µæ•°æ®...")
  homepage_data = fetcher.generate_homepage_data()
  
  if homepage_data:
      fetcher.save_to_file(homepage_data)
      print("ğŸ‰ ä»»åŠ¡å®Œæˆ!")
  else:
      print("âŒ ç”Ÿæˆæ•°æ®å¤±è´¥")

if __name__ == "__main__":
  main()
